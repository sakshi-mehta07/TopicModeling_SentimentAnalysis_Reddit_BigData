{"cells":[{"cell_type":"markdown","id":"ce3ac7bb","metadata":{},"source":["# Understanding Climate Change Discourse on Reddit: A Distributed Analysis of Public Themes, Sentiment, and Recommendations"]},{"cell_type":"markdown","id":"77950fd0","metadata":{},"source":["### Candidate numbers: 39884, 48099, 49308, 50250"]},{"cell_type":"markdown","id":"35f324f0","metadata":{},"source":["## Notebook Overview: Sentiment Classification\n","\n","This notebook continues from the topic modeling analysis and focuses on sentiment analysis on the dataset using a **Logistic Regression classifier**. This classifier was user based on the performance in the comparitive study of sentiment analysis models earlier. The dataset has already been enriched with topic labels and LDA features in the previous `combined_topics.ipynb` notebook. \n","\n","Steps in the notebook:\n","- Load LDA-transformed data (`df_tf_after_topics`) stored in Parquet format.\n","- Label sentiments as Positive, Negative, or Neutral using predefined thresholds on the sentiment polarity score.\n","- Train and evaluate a Logistic Regression model using `rawFeatures` (term frequency vectors) as input.\n","- Save the main dataframe `df_predicted` as a parquet file in a bucket so that it can be imported for the visualisation part of this section.\n"]},{"cell_type":"markdown","id":"f0970a09","metadata":{},"source":["## Cluster Setup and Initialization Actions\n","We used Google Cloud Dataproc to create a scalable cluster with the following settings:\n","\n","#### Create the bucket\n","```gsutil mb gs://st446-gp-sm```\n","\n","#### Upload the initialization script\n","```gsutil cp my_actions.sh gs://st446-gp-sm```\n","\n","#### Create the Dataproc cluster\n","```gcloud dataproc clusters create st446-cluster-project \\\n","  --enable-component-gateway \\\n","  --public-ip-address \\\n","  --region europe-west1 \\\n","  --master-machine-type n2-standard-4 \\\n","  --master-boot-disk-size 100 \\\n","  --num-workers 3 \\\n","  --worker-machine-type n2-standard-4 \\\n","  --worker-boot-disk-size 300 \\\n","  --image-version 2.2-debian12 \\\n","  --optional-components=JUPYTER \\\n","  --metadata 'PIP_PACKAGES=sklearn nltk pandas numpy' \\\n","  --initialization-actions='gs://st446-gp-sm/my_actions.sh' \\\n","  --properties=spark:spark.dynamicAllocation.enabled=true \\\n","--project=capstone-data-1-wto"]},{"cell_type":"code","execution_count":1,"id":"7f589c33","metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gensim\n","  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/default/lib/python3.11/site-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/default/lib/python3.11/site-packages (from gensim) (1.11.4)\n","Collecting smart-open>=1.8.1 (from gensim)\n","  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting wrapt (from smart-open>=1.8.1->gensim)\n","  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.7/26.7 MB\u001B[0m \u001B[31m179.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n","\u001B[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n","Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n","Installing collected packages: wrapt, smart-open, gensim\n","\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3/3\u001B[0m [gensim]2m2/3\u001B[0m [gensim]\n","\u001B[1A\u001B[2KSuccessfully installed gensim-4.3.3 smart-open-7.1.0 wrapt-1.17.2\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\n","\u001B[0mCollecting groq\n","  Downloading groq-0.24.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/default/lib/python3.11/site-packages (from groq) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/default/lib/python3.11/site-packages (from groq) (1.8.0)\n","Collecting httpx<1,>=0.23.0 (from groq)\n","  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/default/lib/python3.11/site-packages (from groq) (2.11.3)\n","Requirement already satisfied: sniffio in /opt/conda/default/lib/python3.11/site-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/conda/default/lib/python3.11/site-packages (from groq) (4.13.2)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/default/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n","Requirement already satisfied: certifi in /opt/conda/default/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n","  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n","Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n","  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/default/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/default/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/default/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n","Downloading groq-0.24.0-py3-none-any.whl (127 kB)\n","Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n","Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n","Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n","Installing collected packages: h11, httpcore, httpx, groq\n","\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4/4\u001B[0m [groq][32m3/4\u001B[0m [groq]\n","\u001B[1A\u001B[2KSuccessfully installed groq-0.24.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["# Import libraries used in this notebook\n","import zipfile\n","!pip install gensim\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","!pip install groq\n","import os\n","from pyspark.sql.functions import when\n","import re\n","import hashlib\n","from datetime import datetime\n","import numpy as np\n","import pandas as pd\n","import string\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import string\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as sql_f \n","from pyspark.ml.feature import CountVectorizer\n","from pyspark.ml.clustering import LDA\n","from time import time\n","from pyspark.sql.functions import udf, col, rand, monotonically_increasing_id\n","from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, ArrayType\n","from pyspark.ml.feature import StopWordsRemover, Tokenizer, CountVectorizer, IDF\n","from pyspark.sql.functions import lower, regexp_replace, row_number, desc\n","import random\n","from pyspark.sql.functions import rand\n","from gensim.corpora import Dictionary\n","from gensim.models.coherencemodel import CoherenceModel\n","from pyspark.sql.functions import year\n","from pyspark.sql.window import Window\n","import matplotlib.pyplot as plt\n","import groq\n","from pyspark.ml.classification import LogisticRegression"]},{"cell_type":"markdown","id":"f9dcd6f0","metadata":{},"source":["# Data Frame Loading after LDA"]},{"cell_type":"code","execution_count":2,"id":"02d9ee0f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- type: string (nullable = true)\n"," |-- id: string (nullable = true)\n"," |-- subreddit.id: string (nullable = true)\n"," |-- subreddit.name: string (nullable = true)\n"," |-- subreddit.nsfw: string (nullable = true)\n"," |-- created_utc: string (nullable = true)\n"," |-- permalink: string (nullable = true)\n"," |-- body: string (nullable = true)\n"," |-- sentiment: double (nullable = true)\n"," |-- score: integer (nullable = true)\n"," |-- body_clean: string (nullable = true)\n"," |-- tokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- filtered: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- final_tokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- rawFeatures: vector (nullable = true)\n"," |-- topicDistribution: vector (nullable = true)\n"," |-- predictedTopic: integer (nullable = true)\n"," |-- docTopWords: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- PredictedTopicName: string (nullable = true)\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-------+-------+------------+-------------------+--------------+-----------+--------------------+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+\n","|   type|     id|subreddit.id|     subreddit.name|subreddit.nsfw|created_utc|           permalink|                body|sentiment|score|          body_clean|              tokens|            filtered|        final_tokens|         rawFeatures|   topicDistribution|predictedTopic|         docTopWords|  PredictedTopicName|\n","+-------+-------+------------+-------------------+--------------+-----------+--------------------+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+\n","|comment|fs7inmj|       2qh13|          worldnews|         false| 1590766155|https://old.reddi...|Both [within](htt...|   -0.765|    2|both within and b...|[both, within, an...|[within, countrie...|[within, countrie...|(26883,[79,294,32...|[0.01464722856476...|             8|[countries, water...|Global Water War ...|\n","|comment|gqor46p|       2qm4e|         askscience|         false| 1615555642|https://old.reddi...|there's no flow u...|   0.6124|   46|there s no flow u...|[there, s, no, fl...|[flow, unless, sn...|[flow, unless, sn...|(26883,[8,29,46,6...|[0.00192470392741...|             3|[warming, global,...|Global Warming Tr...|\n","|comment|eosxrqb|       2sfmf|politicaldiscussion|         false| 1558831329|https://old.reddi...|I’m a conservativ...|   0.4588|    2|i m a conservativ...|[i, m, a, conserv...|[m, conservative,...|[conservative, dr...|(26883,[0,23,169,...|[0.00621703147614...|             5|[think, conservat...|Expressing Politi...|\n","|comment|dnbox8h|       2qht0|         losangeles|         false| 1506025110|https://old.reddi...|I'm LA native. Mo...|  -0.6391|    4|i m la native mos...|[i, m, la, native...|[m, la, native, l...|[native, likely, ...|(26883,[1,2,11,23...|[5.68899610633845...|             4|[world, pretty, l...|Thinking the Worl...|\n","|comment|gytsvbj|       363r3|           beamazed|         false| 1621521624|https://old.reddi...|while the land mo...|   0.7964|    1|while the land mo...|[while, the, land...|[land, likely, wo...|[land, likely, wo...|(26883,[3,54,65,7...|[0.00511331486496...|             8|[water, land, due...|Global Water War ...|\n","+-------+-------+------------+-------------------+--------------+-----------+--------------------+--------------------+---------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# Define the same path\n","input_path = \"gs://st446-gp-sm/processed_data/df_tf_after_topics\"\n","\n","# Load the Parquet data\n","df_tf = spark.read.parquet(input_path)\n","\n","# Check schema\n","df_tf.printSchema()\n","df_tf.show(5)"]},{"cell_type":"markdown","id":"99c9e732","metadata":{},"source":["# Sentiment Analysis"]},{"cell_type":"markdown","id":"1a0cbe93","metadata":{},"source":["## Logistic Regression"]},{"cell_type":"code","execution_count":3,"id":"95c82442","metadata":{"tags":[]},"outputs":[],"source":["df_tf = df_tf.filter(col(\"sentiment\").isNotNull())\n","\n","df_tf = df_tf.withColumn(\n","    \"sentiment_class\",\n","    when(df_tf[\"sentiment\"] > 0.35, 2) #positive\n","    .when(df_tf[\"sentiment\"] < -0.35, 0) #negative\n","    .otherwise(1) #neutral\n",")\n","\n","df_tf = df_tf.withColumn(\n","    \"sentiment_label\",\n","    when(df_tf.sentiment_class == 0, \"Negative\")\n","    .when(df_tf.sentiment_class == 1, \"Neutral\")\n","    .when(df_tf.sentiment_class == 2, \"Positive\")\n",")"]},{"cell_type":"code","execution_count":4,"id":"f9d83208","metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- type: string (nullable = true)\n"," |-- id: string (nullable = true)\n"," |-- subreddit.id: string (nullable = true)\n"," |-- subreddit.name: string (nullable = true)\n"," |-- subreddit.nsfw: string (nullable = true)\n"," |-- created_utc: string (nullable = true)\n"," |-- permalink: string (nullable = true)\n"," |-- body: string (nullable = true)\n"," |-- sentiment: double (nullable = true)\n"," |-- score: integer (nullable = true)\n"," |-- body_clean: string (nullable = true)\n"," |-- tokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- filtered: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- final_tokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- rawFeatures: vector (nullable = true)\n"," |-- topicDistribution: vector (nullable = true)\n"," |-- predictedTopic: integer (nullable = true)\n"," |-- docTopWords: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- PredictedTopicName: string (nullable = true)\n"," |-- sentiment_class: integer (nullable = false)\n"," |-- sentiment_label: string (nullable = true)\n","\n"]}],"source":["df_tf.printSchema()"]},{"cell_type":"code","execution_count":5,"id":"050ff27a","metadata":{"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["25/05/05 09:49:25 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n","25/05/05 09:49:26 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n","25/05/05 09:49:27 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n","25/05/05 09:49:27 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.25\n","25/05/05 09:49:27 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.125\n","25/05/05 09:49:28 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.5\n","25/05/05 09:49:29 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.25\n","25/05/05 09:49:29 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.125\n","25/05/05 09:49:29 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.0625\n","25/05/05 09:49:30 ERROR StrongWolfeLineSearch: Encountered bad values in function evaluation. Decreasing step size to 0.046875\n","25/05/05 09:49:31 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search zoom failed\n"]}],"source":["train_df, test_df = df_tf.randomSplit([0.8, 0.2], seed=42)\n","df_train = train_df.repartition(8)\n","\n","lr = LogisticRegression(\n","    featuresCol=\"rawFeatures\",\n","    labelCol=\"sentiment_class\",\n","    predictionCol=\"PredictionSentiment\",\n","    maxIter=10\n",")\n","\n","lr_model = lr.fit(train_df)"]},{"cell_type":"code","execution_count":6,"id":"bc73b931","metadata":{"tags":[]},"outputs":[],"source":["predictions = lr_model.transform(test_df)"]},{"cell_type":"code","execution_count":7,"id":"eec92a4f","metadata":{"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"sentiment_class\",\n","    predictionCol=\"PredictionSentiment\",\n","    metricName=\"accuracy\"\n",")\n","accuracy = evaluator.evaluate(predictions)"]},{"cell_type":"code","execution_count":8,"id":"d3177b51-8fe6-4e2a-a1ae-b4b2a167eaa0","metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression Results\n","Accuracy:  0.7237\n"]}],"source":["print(\"Logistic Regression Results\")\n","print(f\"Accuracy:  {accuracy:.4f}\")"]},{"cell_type":"markdown","id":"dde0cd09","metadata":{},"source":["### Comment on Model Performance\n","\n","The logistic regression model achieved an **accuracy of ~72.4%**, which is a reasonable result for a 3-class sentiment classification task on social media text, especially using basic text vectorization (term frequency) without advanced embeddings. "]},{"cell_type":"markdown","id":"c73ff982","metadata":{},"source":["## Predicting Sentiment for all documents"]},{"cell_type":"code","execution_count":9,"id":"26a61110","metadata":{},"outputs":[],"source":["df_predicted = lr_model.transform(df_tf)"]},{"cell_type":"code","execution_count":11,"id":"3ae2418a","metadata":{},"outputs":[],"source":["# Add a human-readable label\n","df_predicted = df_predicted.withColumn(\n","    \"predicted_sentiment_label\",\n","    when(col(\"PredictionSentiment\") == 0, \"Negative\")\n","    .when(col(\"PredictionSentiment\") == 1, \"Neutral\")\n","    .when(col(\"PredictionSentiment\") == 2, \"Positive\")\n",")"]},{"cell_type":"code","execution_count":12,"id":"ac245b39","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- type: string (nullable = true)\n"," |-- id: string (nullable = true)\n"," |-- subreddit.id: string (nullable = true)\n"," |-- subreddit.name: string (nullable = true)\n"," |-- subreddit.nsfw: string (nullable = true)\n"," |-- created_utc: string (nullable = true)\n"," |-- permalink: string (nullable = true)\n"," |-- body: string (nullable = true)\n"," |-- sentiment: double (nullable = true)\n"," |-- score: integer (nullable = true)\n"," |-- body_clean: string (nullable = true)\n"," |-- tokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- filtered: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- final_tokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- rawFeatures: vector (nullable = true)\n"," |-- topicDistribution: vector (nullable = true)\n"," |-- predictedTopic: integer (nullable = true)\n"," |-- docTopWords: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- PredictedTopicName: string (nullable = true)\n"," |-- sentiment_class: integer (nullable = false)\n"," |-- sentiment_label: string (nullable = true)\n"," |-- rawPrediction: vector (nullable = true)\n"," |-- probability: vector (nullable = true)\n"," |-- PredictionSentiment: double (nullable = false)\n"," |-- predicted_sentiment_label: string (nullable = true)\n","\n"]}],"source":["df_predicted.printSchema()"]},{"cell_type":"markdown","id":"21ae3408","metadata":{},"source":["# Saving Dataframe with Sentiment Predictions"]},{"cell_type":"code","execution_count":13,"id":"8fb152b9","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Define your output path (change bucket name accordingly)\n","output_path = \"gs://st446-gp-sm/processed_data/df_tf_after_sentiments\"\n","\n","# Save DataFrame as Parquet\n","df_predicted.write.mode(\"overwrite\").parquet(output_path)"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}